{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11d9e205",
   "metadata": {},
   "source": [
    "# Tabular Data Science Course Project: Multiple Theoretical Distributions Fitting to Empirical Distribution Using KDE and Modified KS-Tests\n",
    "## By David Dorfman and Ella Kharakh\n",
    "\n",
    "\n",
    "\n",
    "### Importing the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7fb7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, weibull_min, expon\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb3cb16",
   "metadata": {},
   "source": [
    "### Loading the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80704a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_survival = pd.read_csv(\"./dataset1.csv\", index_col=0)        # pd.read_csv(\"./dataset.csv\", index_col=0)\n",
    "climate_data = pd.read_csv(\"./dataset2.csv\", index_col=0)        # pd.read_csv(\"./daily_data.csv\")\n",
    "predictive_maintenance = pd.read_csv(\"./dataset3.csv\", index_col=0)        # pd.read_csv(\"./predictive-maintenance-dataset.csv\", index_col=0, dtype={'MOU': str})\n",
    "FIFA_23 = pd.read_csv(\"./dataset4.csv\", index_col=0)        # pd.read_csv(\"./fifa_23_280922.csv\", index_col=0)\n",
    "datasets = [patient_survival, climate_data, predictive_maintenance, FIFA_23]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1980651",
   "metadata": {},
   "source": [
    "### Functions for calculating and plotting the KDE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d079535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_kde(feature):\n",
    "    kde = sm.nonparametric.KDEUnivariate(feature)\n",
    "    kde.fit()\n",
    "    return kde\n",
    "\n",
    "\n",
    "def show_kde(feature):\n",
    "    kde = calc_kde(feature)\n",
    "    samples = np.linspace(min(feature), max(feature), 500)\n",
    "    log_prob = kde.evaluate(samples)\n",
    "    plt.plot(samples, np.exp(log_prob), c='green')\n",
    "    # plt.axis([min(feature), max(feature), -0.1, 1.1])\n",
    "    # plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a56756",
   "metadata": {},
   "source": [
    "### Finding the minimum and maximum points for each feature's KDE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4171ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(data):\n",
    "    kde = calc_kde(data)\n",
    "    samples = np.linspace(min(data), max(data), 500)\n",
    "    vals = np.exp(kde.evaluate(samples))\n",
    "    min_list, max_list = [], []\n",
    "    theLastMaxIndex = -1\n",
    "    theLastMinIndex = -1\n",
    "    for i in range(3, len(vals) - 3, 1):\n",
    "        if vals[i] == np.max(vals[i - 3: i + 3]):\n",
    "            max_list.append((samples[i], vals[i]))\n",
    "            theLastMaxIndex = i\n",
    "        elif vals[i] == np.min(vals[i - 3: i + 3]):\n",
    "            min_list.append((samples[i], vals[i]))\n",
    "            theLastMinIndex = i\n",
    "        if (len(min_list) == 0) and (len(max_list) != 0):\n",
    "            min_list.append((samples[0], vals[0]))\n",
    "        if (len(min_list) != 0) and (len(max_list) == 0):\n",
    "            max_list.append((samples[0], vals[0]))\n",
    "    if theLastMaxIndex > theLastMinIndex:\n",
    "        min_list.append((samples[len(samples)-1], vals[len(samples)-1]))\n",
    "    else:\n",
    "        max_list.append((samples[len(samples)-1], vals[len(samples)-1]))\n",
    "    return min_list, max_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af7228",
   "metadata": {},
   "source": [
    "### Filtering the Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a9fd7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(dataset):\n",
    "    num_features = dataset.select_dtypes(include=[np.number])\n",
    "    column_names = list(num_features.columns.values)\n",
    "    uni_features = [f for f in column_names if dataset[f].nunique() > 50 and dataset[f].isna().sum() / len(dataset[f])\\\n",
    "                    < 0.4 and dataset[f].nunique() < len(dataset[f])]\n",
    "    min_max_features = {}\n",
    "    for f in uni_features:\n",
    "        feature = dataset[f].fillna(dataset[f].mean())\n",
    "        min_max_features[f] = min_max(feature.to_numpy())\n",
    "    rel_features = [f for f in min_max_features if len(min_max_features[f][0]) > 1 and len(min_max_features[f][1]) > 1]\n",
    "    return rel_features\n",
    "\n",
    "\n",
    "filtered_patient = filter_dataset(patient_survival)\n",
    "filtered_climate = filter_dataset(climate_data)\n",
    "filtered_maintenance = filter_dataset(predictive_maintenance)\n",
    "filtered_FIFA = filter_dataset(FIFA_23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be18a8",
   "metadata": {},
   "source": [
    "### Ploting the relevant KDEs for the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2b73ef47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** patient survival dataset ***\n",
      "*** climate data dataset ***\n",
      "*** predictive maintenance dataset ***\n",
      "*** FIFA 23 dataset ***\n"
     ]
    }
   ],
   "source": [
    "print(\"*** patient survival dataset ***\")\n",
    "\n",
    "for feature in filtered_patient:\n",
    "    print(feature)\n",
    "    show_kde(patient_survival[feature])\n",
    "\n",
    "print(\"*** climate data dataset ***\")\n",
    "\n",
    "for feature in filtered_climate:\n",
    "    print(feature)\n",
    "    show_kde(climate_data[feature])\n",
    "\n",
    "print(\"*** predictive maintenance dataset ***\")\n",
    "\n",
    "for feature in filtered_maintenance:\n",
    "    print(feature)\n",
    "    show_kde(predictive_maintenance[feature])\n",
    "\n",
    "print(\"*** FIFA 23 dataset ***\")\n",
    "\n",
    "for feature in filtered_FIFA:\n",
    "    print(feature)\n",
    "    show_kde(FIFA_23[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d0a856",
   "metadata": {},
   "source": [
    "### Functions for the KS tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ed72d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_test_exp(empirical):\n",
    "    params = stats.expon.fit(empirical)\n",
    "    result = stats.kstest(empirical, lambda x: stats.expon.cdf(x, loc=params[0], scale=params[1]))\n",
    "    return result\n",
    "\n",
    "\n",
    "def ks_test_weibull(empirical):\n",
    "    params = stats.weibull_min.fit(empirical)\n",
    "    return stats.kstest(empirical, lambda x: stats.weibull_min.cdf(x, c=params[0], loc=params[1], scale=params[2]))\n",
    "\n",
    "\n",
    "def ks_test_normal(empirical):\n",
    "    params = stats.norm.fit(empirical)\n",
    "    return stats.kstest(empirical, lambda x: stats.norm.cdf(x, loc=params[0], scale=params[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74594140",
   "metadata": {},
   "source": [
    "### Function for getting a subset of a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51015cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subSetOfDomain(ourFeature, intervalSmallerParm, intervalBigParm):\n",
    "    sub_list = ourFeature\n",
    "    listToReturn = list()\n",
    "    for val in sub_list:\n",
    "        if (val <= intervalBigParm and val >= intervalSmallerParm):\n",
    "            listToReturn.append(val)\n",
    "    return listToReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8962db3",
   "metadata": {},
   "source": [
    "### Function for calculating the weighted average of the P-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e7cd8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedArithmeticMeanPvalues(listOfPvalues, listOfTheirWeights):\n",
    "    sum = 0\n",
    "    for i in range(len(listOfPvalues)):\n",
    "        sum += listOfPvalues[i] * listOfTheirWeights[i]\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db240e9",
   "metadata": {},
   "source": [
    "### Function for evaluating the best P-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "586f6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pValueEvaluator(feature, begin, end):\n",
    "    ourInterval = subSetOfDomain(feature, begin, end)\n",
    "    if len(ourInterval) / len(feature) > 0.05:\n",
    "        result1 = ks_test_exp(ourInterval).pvalue\n",
    "        result2 = ks_test_weibull(ourInterval).pvalue\n",
    "        result3 = ks_test_normal(ourInterval).pvalue\n",
    "        tempMax = max(result1, result2, result3)\n",
    "        if tempMax < 0.05:\n",
    "            return 0, \"no theoretical distribution\"\n",
    "        if result1 == tempMax:\n",
    "            return result1, \"Exponential distribution\"\n",
    "        if result2 == tempMax:\n",
    "            return result2, \"Weibull distribution\"\n",
    "        if result3 == tempMax:\n",
    "            return result3, \"Normal distribution\" \n",
    "    return 0, \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ff2303",
   "metadata": {},
   "source": [
    "### Function for checking if we should expand or narrow the interval by 10% or keep the interval as is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "161ed222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isBetterRangOfPvalue(ourFeature, begin, end):\n",
    "    baseFeature = (begin, end)\n",
    "    num1 = updatenumberToCeil(end,  1.1)\n",
    "    if num1 >= len(ourFeature):\n",
    "        num1 = len(ourFeature)-1\n",
    "    num2 = updatenumberToFloor(begin, 0.9)\n",
    "    if num2 < 0:\n",
    "        num2 = 0\n",
    "    num3 = updatenumberToFloor(end, 0.9)\n",
    "    num4 = updatenumberToCeil(begin, 1.1)\n",
    "    valueBaseFeature = pValueEvaluator(ourFeature, begin, end)\n",
    "    valf1 = pValueEvaluator(ourFeature, begin, num1)\n",
    "    valf2 = pValueEvaluator(ourFeature, num2, end)\n",
    "    valf3 = pValueEvaluator(ourFeature, begin, num3)\n",
    "    valf4 = pValueEvaluator(ourFeature, num4, end)\n",
    "    maxValue = max(valueBaseFeature[0], valf1[0], valf2[0], valf3[0], valf4[0])\n",
    "    if maxValue == valueBaseFeature[0]:\n",
    "        return baseFeature, valueBaseFeature\n",
    "    if maxValue == valf1[0]:\n",
    "        return (begin, num1), valf1\n",
    "    if maxValue == valf2[0]:\n",
    "        return (num2, end), valf2\n",
    "    if maxValue == valf3[0]:\n",
    "        return (begin, num3), valf3\n",
    "    return (num4, end), valf4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf75fa41",
   "metadata": {},
   "source": [
    "### Helper functions for rounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23694b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updatenumberToCeil(num, precentageofchange):\n",
    "    num = num * precentageofchange\n",
    "    return math.ceil(num)\n",
    "\n",
    "\n",
    "def updatenumberToFloor(num, precentageofchange):\n",
    "    num = num * precentageofchange\n",
    "    return math.floor(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e9260",
   "metadata": {},
   "source": [
    "### Function for finding the best ranges based on the P-values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c01fa98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestPvalueRanges(feature):\n",
    "    min_list, max_list = min_max(feature)\n",
    "    listOfRanges = list()\n",
    "    j = 0\n",
    "    i = 0\n",
    "    while i < len(min_list) and j < len(max_list):\n",
    "        if min_list[i][0] < max_list[j][0]:\n",
    "            listOfRanges.append(((min_list[i][0], max_list[j][0]), pValueEvaluator(feature, min_list[i][0], max_list[j][0])))\n",
    "            i = i + 1\n",
    "            if i < len(min_list):\n",
    "                listOfRanges.append(((min_list[i-1][0], min_list[i][0]), pValueEvaluator(feature, min_list[i-1][0], min_list[i][0])))\n",
    "        else:\n",
    "            listOfRanges.append(((max_list[j][0], min_list[i][0]), pValueEvaluator(feature, max_list[j][0], min_list[i][0])))\n",
    "            j = j + 1\n",
    "    return changeIntervals(listOfRanges, feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f1641",
   "metadata": {},
   "source": [
    "### Function for plotting the KDE divided by distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f907d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showGraphOfDistrebutions(intervals, feature, name):\n",
    "    kde = calc_kde(feature)\n",
    "    samples = np.linspace(0, max(feature), 6000)\n",
    "    log_prob = kde.evaluate(samples)\n",
    "    x = np.sort(feature)\n",
    "    y = np.exp(log_prob)\n",
    "    colors = ['blue', 'green', 'orange', 'pink', 'red', 'purple', 'pink', 'turquoise']\n",
    "    figure, axes = plt.subplots()\n",
    "    for i, interval in enumerate(intervals):\n",
    "        j = i\n",
    "        if i > len(colors) - 1:\n",
    "            j = i % len(colors)\n",
    "        mask = np.logical_and(samples >= interval[0][0], samples <= interval[0][1])\n",
    "        plt.plot(samples[mask], np.exp(log_prob[mask]), c=colors[i])\n",
    "    axes.legend()\n",
    "    axes.set_title(str(name))\n",
    "    for i, interval in enumerate(intervals):\n",
    "        x_center = np.mean(interval[0])\n",
    "        y_center = np.max(y) * 1.2\n",
    "        axes.text(x_center, y_center, f'{interval[1][1]}', ha='center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8a6dee",
   "metadata": {},
   "source": [
    "### Function for picking the best intervals to start from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "82129b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestIntervalsToCheck(listOfRanges, feature):\n",
    "    listToReturn = list()\n",
    "    lengthOfFeature = max(feature) - min(feature)\n",
    "    isFirstTime = 1\n",
    "    for i in range(len(listOfRanges)):\n",
    "        if i+1 < len(listOfRanges) and i+2 < len(listOfRanges):\n",
    "            if listOfRanges[i][0][0] == listOfRanges[i+1][0][0] and listOfRanges[i+2][0][1] == listOfRanges[i+1][0][1]:\n",
    "                lengthOfInterval1 = (listOfRanges[i][0][1] - listOfRanges[i][0][0])/lengthOfFeature\n",
    "                lengthOfInterval2 = (listOfRanges[i+1][0][1] - listOfRanges[i+1][0][0])/lengthOfFeature\n",
    "                lengthOfInterval3 = (listOfRanges[i+2][0][1] - listOfRanges[i+2][0][0])/lengthOfFeature\n",
    "                weightedPvalue1 = lengthOfInterval1 * listOfRanges[i][1][0]\n",
    "                weightedPvalue2 = lengthOfInterval2 * listOfRanges[i+1][1][0]\n",
    "                weightedPvalue3 = lengthOfInterval3 * listOfRanges[i+2][1][0]\n",
    "                tempMax = max(weightedPvalue1, weightedPvalue2, weightedPvalue3)\n",
    "                if weightedPvalue1 == tempMax:\n",
    "                    listToReturn.append(listOfRanges[i])\n",
    "                elif weightedPvalue2 == tempMax:\n",
    "                    listToReturn.append(listOfRanges[i+1])\n",
    "                elif weightedPvalue3 == tempMax:\n",
    "                    listToReturn.append(listOfRanges[i+2])\n",
    "                isFirstTime = 0\n",
    "                if i+2 == len(listOfRanges) - 1:\n",
    "                    i = len(listOfRanges)\n",
    "            elif isFirstTime or i == len(listOfRanges) - 1:\n",
    "                isFirstTime = 0\n",
    "                listToReturn.append(listOfRanges[i])\n",
    "    return listToReturn\n",
    "\n",
    "\n",
    "def bestVersionOfInterval(rang, feature):\n",
    "    pValueinteval1 = rang\n",
    "    tempPvalue = isBetterRangOfPvalue(feature, rang[0][0], rang[0][1])\n",
    "    while (tempPvalue[1][0] > pValueinteval1[1][0]):\n",
    "        pValueinteval1 = tempPvalue\n",
    "        tempPvalue = isBetterRangOfPvalue(feature, pValueinteval1[0][0], pValueinteval1[0][1])\n",
    "    return pValueinteval1\n",
    "\n",
    "\n",
    "def adjustIntervals(listOfRanges, feature):\n",
    "    listToReturn = list()\n",
    "    for rang in listOfRanges:\n",
    "        rang11 = bestVersionOfInterval(rang, feature)\n",
    "        if rang11[1][0] != 0:\n",
    "            listToReturn.append(rang11)\n",
    "    return listToReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8743c55",
   "metadata": {},
   "source": [
    "### Functions for treatment in overlaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e34f4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursiveCareOfOvelap(feature, rang1, rang2, pvalue1, reqDepth):\n",
    "    num1 = ((rang1[0][1] - rang2[0][0])/2)\n",
    "    pValueInterval1 = (rang2[0][0] + num1 - rang1[0][0]) * (pValueEvaluator(feature, rang1[0][0], rang2[0][0] + num1)[0])\n",
    "    pValueInterval2 = (rang2[0][1] - rang2[0][0] - num1) * (pValueEvaluator(feature, rang2[0][0] + num1, rang2[0][1])[0])\n",
    "    pvalueNew = pValueInterval1 + pValueInterval2\n",
    "    if pvalue1 - pvalueNew >= 0.01 or reqDepth >= 300:\n",
    "        return rang1, rang2\n",
    "    else:\n",
    "        rang1 = ((rang1[0][0], rang2[0][0] + num1), pValueEvaluator(feature, rang1[0][0], rang2[0][0] + num1))\n",
    "        rang2 = ((rang2[0][0] + num1, rang2[0][1]), pValueEvaluator(feature, rang2[0][0] + num1, rang2[0][1]))\n",
    "        pvalue1 = pvalueNew\n",
    "        return recursiveCareOfOvelap(feature, rang1, rang2, pvalue1, reqDepth + 1)\n",
    "    \n",
    "\n",
    "def careOfOverlap(interval1, interval2, feature):\n",
    "    num1 = ((interval1[0][1] - interval2[0][0])/2)\n",
    "    pValueInterval1 = (interval2[0][0] + num1 - interval1[0][0]) * (pValueEvaluator(feature, interval1[0][0], interval2[0][0] + num1)[0])\n",
    "    pValueInterval2 = (interval2[0][1] - interval2[0][0] - num1) * (pValueEvaluator(feature, interval2[0][0] + num1, interval2[0][1])[0])\n",
    "    pvalueNew = pValueInterval1 + pValueInterval2\n",
    "    pvalueOriginal = ((interval1[0][1] - interval1[0][0]) * interval1[1][0]) + ((interval2[0][1] - interval1[0][1]) * (pValueEvaluator(feature, interval1[0][1], interval2[0][1])[0]))\n",
    "    if pvalueNew <= pvalueOriginal:\n",
    "        rang1 = interval1\n",
    "        rang2 = ((interval1[0][1], interval2[0][1]), pValueEvaluator(feature, interval1[0][1], interval2[0][1]))\n",
    "        return rang1, rang2\n",
    "    else:\n",
    "        rang1 = ((interval1[0][0], interval2[0][0] + num1), pValueEvaluator(feature, interval1[0][0], interval2[0][0] + num1))\n",
    "        rang2 = ((interval2[0][0] + num1, interval2[0][1]), pValueEvaluator(feature, interval2[0][0] + num1, interval2[0][1]))\n",
    "        return recursiveCareOfOvelap(feature, rang1, rang2, pvalueNew, 0)\n",
    "\n",
    "\n",
    "def eraseOverlaps(listOfRanges, feature):\n",
    "    i = 1\n",
    "    newList = list()\n",
    "    currentRange = listOfRanges[0]\n",
    "    while i < len(listOfRanges):\n",
    "        nextRange = listOfRanges[i]\n",
    "        if ((currentRange[0][0] <= nextRange[0][0]) and (currentRange[0][1] >= nextRange[0][0])) or ((currentRange[0][0] >= nextRange[0][1]) and (currentRange[0][1] >= nextRange[0][1])):\n",
    "            rang1, rang2 = careOfOverlap(currentRange, nextRange, feature)\n",
    "            newList.append(rang1)\n",
    "            currentRange = rang2\n",
    "        else:\n",
    "            newList.append(currentRange)\n",
    "            currentRange = nextRange\n",
    "        i = i + 1\n",
    "    if currentRange not in newList:\n",
    "        newList.append(currentRange)\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5141352e",
   "metadata": {},
   "source": [
    "### Functions for treatment in gaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bdccf45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursiveCareOfGaps(feature, interval1, interval2, pvalue1, reqDepth):\n",
    "    num1 = ((interval1[0][1] - interval2[0][0])/2)\n",
    "    pValueInterval1 = (interval1[0][1] + num1 - interval1[0][0]) * (pValueEvaluator(feature, interval1[0][0], interval1[0][1] + num1)[0])\n",
    "    pValueInterval2 = (interval2[0][1] - interval2[0][0] + num1) * (pValueEvaluator(feature, interval2[0][0] - num1, interval2[0][1])[0])\n",
    "    pvalueNew = pValueInterval1 + pValueInterval2\n",
    "    if pvalue1 - pvalueNew >= 0.000001 or reqDepth>=300:\n",
    "        return interval1, interval2\n",
    "    else:\n",
    "        rang1 = ((interval1[0][0], interval1[0][1] + num1), pValueEvaluator(feature, interval1[0][0], interval1[0][1] + num1))\n",
    "        rang2 = ((interval2[0][0] - num1, interval2[0][1]), pValueEvaluator(feature, interval2[0][0] - num1, interval2[0][1]))\n",
    "        pvalue1 = pvalueNew\n",
    "        return recursiveCareOfGaps(feature, rang1, rang2, pvalueNew, reqDepth + 1)\n",
    "\n",
    "\n",
    "def careOfGaps(interval1, interval2, feature):\n",
    "    num1 = ((interval2[0][0] - interval1[0][1])/2)\n",
    "    pValueInterval1 = (interval1[0][1] + num1 - interval1[0][0]) * (pValueEvaluator(feature, interval1[0][0], interval1[0][1] + num1)[0])\n",
    "    pValueInterval2 = (interval2[0][1] - interval2[0][0] + num1) * (pValueEvaluator(feature, interval2[0][0] - num1, interval2[0][1])[0])\n",
    "    pvalueNew = pValueInterval1 + pValueInterval2\n",
    "    pvalueOriginal1 = ((interval1[0][1] - interval1[0][0]) * interval1[1][0]) + ((interval2[0][1] - interval1[0][1]) * (pValueEvaluator(feature, interval1[0][1], interval2[0][1])[0]))\n",
    "    pvalueOriginal2 = ((interval2[0][1] - interval2[0][0]) * interval2[1][0]) + ((interval2[0][0] - interval1[0][0]) * (pValueEvaluator(feature, interval1[0][0], interval2[0][0])[0]))\n",
    "    tempMax = max(pvalueOriginal1, pvalueOriginal2, pvalueNew)\n",
    "    if pvalueOriginal1 == tempMax:\n",
    "        rang1 = interval1\n",
    "        rang2 = ((interval1[0][1], interval2[0][1]), pValueEvaluator(feature, interval1[0][1], interval2[0][1]))\n",
    "        return rang1, rang2\n",
    "    elif pvalueOriginal2 == tempMax:\n",
    "        rang2 = interval2\n",
    "        rang1 = (interval1[0][0], interval2[0][0]), pValueEvaluator(feature, interval1[0][0], interval2[0][0])\n",
    "        return rang1, rang2\n",
    "    else:\n",
    "        rang1 = ((interval1[0][0], interval1[0][1] + num1), pValueEvaluator(feature, interval1[0][0], interval1[0][1] + num1))\n",
    "        rang2 = ((interval2[0][0] - num1, interval2[0][1]), pValueEvaluator(feature, interval2[0][0] - num1, interval2[0][1]))\n",
    "        return recursiveCareOfGaps(feature, rang1, rang2, pvalueNew, 0)\n",
    "\n",
    "\n",
    "def eraseGaps(listOfRanges, feature):\n",
    "    i = 1\n",
    "    newList = list()\n",
    "    currentRange = listOfRanges[0]\n",
    "    if currentRange[0][0] != 0:\n",
    "        currentRange = ((0, currentRange[0][1]), pValueEvaluator(feature, 0, currentRange[0][1]))\n",
    "    while i < len(listOfRanges):\n",
    "        nextRange = listOfRanges[i]\n",
    "        if currentRange[0][1] < nextRange[0][1]:\n",
    "            rang1, rang2 = careOfGaps(currentRange, nextRange, feature)\n",
    "            newList.append(rang1)\n",
    "            currentRange = rang2\n",
    "        else:\n",
    "            newList.append(currentRange)\n",
    "            currentRange = nextRange\n",
    "        i = i + 1\n",
    "    if currentRange not in newList:\n",
    "        newList.append(currentRange)\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008f486",
   "metadata": {},
   "source": [
    "### Function for finding the best partition to distributions of the KDE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a74f515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeIntervals(listOfRanges, feature):\n",
    "    listOfRangesUpdated = bestIntervalsToCheck(listOfRanges, feature)\n",
    "    listOfRangesUpdated = adjustIntervals(listOfRangesUpdated, feature)\n",
    "    listOfRangesUpdated = eraseOverlaps(listOfRangesUpdated, feature)\n",
    "    listOfRangesUpdated = eraseGaps(listOfRangesUpdated, feature)\n",
    "    return listOfRangesUpdated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de484c",
   "metadata": {},
   "source": [
    "### Function for calculating the score of our method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad608167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upgradedKsCalc(feature):\n",
    "    ranges = bestPvalueRanges(feature)\n",
    "    listOfWeights = list()\n",
    "    listOfPvalues = list()\n",
    "    lengthOfFeature = max(feature)\n",
    "    for i in range(len(ranges)):\n",
    "        listOfPvalues.append(ranges[i][1][0])\n",
    "        listOfWeights.append((ranges[i][0][1] - ranges[i][0][0])/lengthOfFeature)\n",
    "    pvalueOfFeature = weightedArithmeticMeanPvalues(listOfPvalues, listOfWeights)\n",
    "    return pvalueOfFeature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356ac230",
   "metadata": {},
   "source": [
    "### Comparing the results between our solution and the regular solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df375ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the result of every solutuon\n",
    "def run_solutions(feature):\n",
    "    ourSolution = upgradedKsCalc(feature)\n",
    "    traditionalSolution = max(ks_test_exp(feature).pvalue, ks_test_normal(feature).pvalue, ks_test_weibull(feature).pvalue)   # stats.kstest(feature)\n",
    "    return ourSolution, traditionalSolution\n",
    "\n",
    "# testing the data\n",
    "def test():\n",
    "    feature = generate_data()\n",
    "    ourSolution = upgradedKsCalc(feature)\n",
    "    traditionalSolution = max(ks_test_exp(feature).pvalue, ks_test_normal(feature).pvalue, ks_test_weibull(feature).pvalue)\n",
    "    print(\"our solution: \" + str(ourSolution))\n",
    "    print(\"original solution: \" + str(traditionalSolution))\n",
    "    ranges = bestPvalueRanges(feature)\n",
    "    showGraphOfDistrebutions(ranges, feature, \"sample\")\n",
    "\n",
    "\n",
    "# testing the graph\n",
    "def testGraph(feature, name):\n",
    "    ranges = bestPvalueRanges(feature)\n",
    "    showGraphOfDistrebutions(ranges, feature, name)\n",
    "\n",
    "\n",
    "dataset0 = pd.read_csv(\"./dataset1.csv\")\n",
    "feature0 = dataset0['feature1'].tolist()\n",
    "# testGraph(feature0, \"dataset1\")\n",
    "answer0 = run_solutions(feature0)\n",
    "print(\"Dataset 1:\")\n",
    "print(\"our solution:\", str(answer0[0]))\n",
    "print(\"taraditional solution:\", str(answer0[1]))\n",
    "\n",
    "dataset1 = pd.read_csv(\"./dataset2.csv\")\n",
    "feature1 = dataset1['feature1'].tolist()\n",
    "# testGraph(feature1, \"dataset2\")\n",
    "answer1 = run_solutions(feature1)\n",
    "print(\"Dataset 2:\")\n",
    "print(\"our solution:\", str(answer1[0]))\n",
    "print(\"taraditional solution:\", str(answer1[1]))\n",
    "\n",
    "dataset2 = pd.read_csv(\"./dataset3.csv\")\n",
    "feature2 = dataset2['feature1'].tolist()\n",
    "# testGraph(feature2, \"dataset3\")\n",
    "answer2 = run_solutions(feature2)\n",
    "print(\"Dataset 3:\")\n",
    "print(\"our solution:\", str(answer2[0]))\n",
    "print(\"taraditional solution:\", str(answer2[1]))\n",
    "\n",
    "dataset3 = pd.read_csv(\"./dataset4.csv\")\n",
    "feature3 = dataset3['feature1'].tolist()\n",
    "# testGraph(feature3, \"dataset4\")\n",
    "answer3 = run_solutions(feature3)\n",
    "print(\"Dataset 4:\")\n",
    "print(\"our solution:\", str(answer3[0]))\n",
    "print(\"taraditional solution:\", str(answer3[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
